{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, transform=mnist_transforms, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, transform=mnist_transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mnist_train[0][0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"Convnet Classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.clf(self.conv(x).squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "if cuda_available:\n",
    "    clf = clf.cuda()\n",
    "optimizer = torch.optim.Adam(clf.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 1.428 \n",
      "Epoch : 0 Loss : 1.265 \n",
      "Epoch : 0 Loss : 1.075 \n",
      "Epoch : 0 Loss : 0.943 \n",
      "Epoch : 0 Loss : 0.850 \n",
      "Epoch : 0 Loss : 0.778 \n",
      "Epoch : 0 Loss : 0.723 \n",
      "Epoch : 0 Loss : 0.676 \n",
      "Epoch : 0 Loss : 0.637 \n",
      "Epoch : 0 Loss : 0.604 \n",
      "Epoch : 0 Loss : 0.574 \n",
      "Epoch : 0 Loss : 0.550 \n",
      "Epoch : 0 Loss : 0.527 \n",
      "Epoch : 0 Loss : 0.508 \n",
      "Epoch : 0 Loss : 0.489 \n",
      "Epoch : 0 Loss : 0.474 \n",
      "Epoch : 0 Loss : 0.460 \n",
      "Epoch : 0 Loss : 0.446 \n",
      "Epoch : 0 Loss : 0.434 \n",
      "Epoch : 0 Test Acc : 93.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 1 Loss : 2.422 \n",
      "Epoch : 1 Loss : 1.399 \n",
      "Epoch : 1 Loss : 0.968 \n",
      "Epoch : 1 Loss : 0.797 \n",
      "Epoch : 1 Loss : 0.695 \n",
      "Epoch : 1 Loss : 0.639 \n",
      "Epoch : 1 Loss : 0.596 \n",
      "Epoch : 1 Loss : 0.568 \n",
      "Epoch : 1 Loss : 0.545 \n",
      "Epoch : 1 Loss : 0.526 \n",
      "Epoch : 1 Loss : 0.510 \n",
      "Epoch : 1 Loss : 0.494 \n",
      "Epoch : 1 Loss : 0.482 \n",
      "Epoch : 1 Loss : 0.471 \n",
      "Epoch : 1 Loss : 0.461 \n",
      "Epoch : 1 Loss : 0.451 \n",
      "Epoch : 1 Loss : 0.441 \n",
      "Epoch : 1 Loss : 0.434 \n",
      "Epoch : 1 Loss : 0.426 \n",
      "Epoch : 1 Test Acc : 95.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 2 Loss : 0.232 \n",
      "Epoch : 2 Loss : 0.300 \n",
      "Epoch : 2 Loss : 0.306 \n",
      "Epoch : 2 Loss : 0.298 \n",
      "Epoch : 2 Loss : 0.292 \n",
      "Epoch : 2 Loss : 0.290 \n",
      "Epoch : 2 Loss : 0.290 \n",
      "Epoch : 2 Loss : 0.289 \n",
      "Epoch : 2 Loss : 0.290 \n",
      "Epoch : 2 Loss : 0.286 \n",
      "Epoch : 2 Loss : 0.287 \n",
      "Epoch : 2 Loss : 0.287 \n",
      "Epoch : 2 Loss : 0.287 \n",
      "Epoch : 2 Loss : 0.285 \n",
      "Epoch : 2 Loss : 0.285 \n",
      "Epoch : 2 Loss : 0.283 \n",
      "Epoch : 2 Loss : 0.284 \n",
      "Epoch : 2 Loss : 0.283 \n",
      "Epoch : 2 Loss : 0.281 \n",
      "Epoch : 2 Test Acc : 95.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 3 Loss : 0.133 \n",
      "Epoch : 3 Loss : 0.239 \n",
      "Epoch : 3 Loss : 0.260 \n",
      "Epoch : 3 Loss : 0.263 \n",
      "Epoch : 3 Loss : 0.256 \n",
      "Epoch : 3 Loss : 0.252 \n",
      "Epoch : 3 Loss : 0.251 \n",
      "Epoch : 3 Loss : 0.249 \n",
      "Epoch : 3 Loss : 0.250 \n",
      "Epoch : 3 Loss : 0.247 \n",
      "Epoch : 3 Loss : 0.247 \n",
      "Epoch : 3 Loss : 0.246 \n",
      "Epoch : 3 Loss : 0.246 \n",
      "Epoch : 3 Loss : 0.245 \n",
      "Epoch : 3 Loss : 0.246 \n",
      "Epoch : 3 Loss : 0.244 \n",
      "Epoch : 3 Loss : 0.243 \n",
      "Epoch : 3 Loss : 0.242 \n",
      "Epoch : 3 Loss : 0.241 \n",
      "Epoch : 3 Test Acc : 96.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 4 Loss : 0.201 \n",
      "Epoch : 4 Loss : 0.244 \n",
      "Epoch : 4 Loss : 0.229 \n",
      "Epoch : 4 Loss : 0.221 \n",
      "Epoch : 4 Loss : 0.222 \n",
      "Epoch : 4 Loss : 0.221 \n",
      "Epoch : 4 Loss : 0.219 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.216 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.216 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.215 \n",
      "Epoch : 4 Loss : 0.214 \n",
      "Epoch : 4 Test Acc : 96.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 5 Loss : 0.157 \n",
      "Epoch : 5 Loss : 0.199 \n",
      "Epoch : 5 Loss : 0.196 \n",
      "Epoch : 5 Loss : 0.204 \n",
      "Epoch : 5 Loss : 0.202 \n",
      "Epoch : 5 Loss : 0.198 \n",
      "Epoch : 5 Loss : 0.195 \n",
      "Epoch : 5 Loss : 0.199 \n",
      "Epoch : 5 Loss : 0.200 \n",
      "Epoch : 5 Loss : 0.200 \n",
      "Epoch : 5 Loss : 0.199 \n",
      "Epoch : 5 Loss : 0.197 \n",
      "Epoch : 5 Loss : 0.196 \n",
      "Epoch : 5 Loss : 0.196 \n",
      "Epoch : 5 Loss : 0.198 \n",
      "Epoch : 5 Loss : 0.198 \n",
      "Epoch : 5 Loss : 0.197 \n",
      "Epoch : 5 Loss : 0.196 \n",
      "Epoch : 5 Loss : 0.196 \n",
      "Epoch : 5 Test Acc : 97.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 6 Loss : 0.186 \n",
      "Epoch : 6 Loss : 0.173 \n",
      "Epoch : 6 Loss : 0.171 \n",
      "Epoch : 6 Loss : 0.178 \n",
      "Epoch : 6 Loss : 0.181 \n",
      "Epoch : 6 Loss : 0.181 \n",
      "Epoch : 6 Loss : 0.181 \n",
      "Epoch : 6 Loss : 0.181 \n",
      "Epoch : 6 Loss : 0.180 \n",
      "Epoch : 6 Loss : 0.179 \n",
      "Epoch : 6 Loss : 0.178 \n",
      "Epoch : 6 Loss : 0.178 \n",
      "Epoch : 6 Loss : 0.177 \n",
      "Epoch : 6 Loss : 0.176 \n",
      "Epoch : 6 Loss : 0.174 \n",
      "Epoch : 6 Loss : 0.174 \n",
      "Epoch : 6 Loss : 0.174 \n",
      "Epoch : 6 Loss : 0.173 \n",
      "Epoch : 6 Loss : 0.173 \n",
      "Epoch : 6 Test Acc : 97.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 7 Loss : 0.232 \n",
      "Epoch : 7 Loss : 0.146 \n",
      "Epoch : 7 Loss : 0.156 \n",
      "Epoch : 7 Loss : 0.167 \n",
      "Epoch : 7 Loss : 0.164 \n",
      "Epoch : 7 Loss : 0.165 \n",
      "Epoch : 7 Loss : 0.167 \n",
      "Epoch : 7 Loss : 0.170 \n",
      "Epoch : 7 Loss : 0.168 \n",
      "Epoch : 7 Loss : 0.169 \n",
      "Epoch : 7 Loss : 0.169 \n",
      "Epoch : 7 Loss : 0.170 \n",
      "Epoch : 7 Loss : 0.168 \n",
      "Epoch : 7 Loss : 0.169 \n",
      "Epoch : 7 Loss : 0.167 \n",
      "Epoch : 7 Loss : 0.166 \n",
      "Epoch : 7 Loss : 0.165 \n",
      "Epoch : 7 Loss : 0.164 \n",
      "Epoch : 7 Loss : 0.164 \n",
      "Epoch : 7 Test Acc : 97.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 8 Loss : 0.119 \n",
      "Epoch : 8 Loss : 0.149 \n",
      "Epoch : 8 Loss : 0.149 \n",
      "Epoch : 8 Loss : 0.149 \n",
      "Epoch : 8 Loss : 0.152 \n",
      "Epoch : 8 Loss : 0.150 \n",
      "Epoch : 8 Loss : 0.149 \n",
      "Epoch : 8 Loss : 0.151 \n",
      "Epoch : 8 Loss : 0.152 \n",
      "Epoch : 8 Loss : 0.153 \n",
      "Epoch : 8 Loss : 0.153 \n",
      "Epoch : 8 Loss : 0.153 \n",
      "Epoch : 8 Loss : 0.151 \n",
      "Epoch : 8 Loss : 0.152 \n",
      "Epoch : 8 Loss : 0.152 \n",
      "Epoch : 8 Loss : 0.152 \n",
      "Epoch : 8 Loss : 0.152 \n",
      "Epoch : 8 Loss : 0.152 \n",
      "Epoch : 8 Loss : 0.153 \n",
      "Epoch : 8 Test Acc : 97.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 9 Loss : 0.127 \n",
      "Epoch : 9 Loss : 0.153 \n",
      "Epoch : 9 Loss : 0.145 \n",
      "Epoch : 9 Loss : 0.156 \n",
      "Epoch : 9 Loss : 0.157 \n",
      "Epoch : 9 Loss : 0.155 \n",
      "Epoch : 9 Loss : 0.152 \n",
      "Epoch : 9 Loss : 0.151 \n",
      "Epoch : 9 Loss : 0.150 \n",
      "Epoch : 9 Loss : 0.147 \n",
      "Epoch : 9 Loss : 0.148 \n",
      "Epoch : 9 Loss : 0.146 \n",
      "Epoch : 9 Loss : 0.148 \n",
      "Epoch : 9 Loss : 0.148 \n",
      "Epoch : 9 Loss : 0.148 \n",
      "Epoch : 9 Loss : 0.147 \n",
      "Epoch : 9 Loss : 0.147 \n",
      "Epoch : 9 Loss : 0.148 \n",
      "Epoch : 9 Loss : 0.147 \n",
      "Epoch : 9 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 10 Loss : 0.129 \n",
      "Epoch : 10 Loss : 0.142 \n",
      "Epoch : 10 Loss : 0.141 \n",
      "Epoch : 10 Loss : 0.144 \n",
      "Epoch : 10 Loss : 0.142 \n",
      "Epoch : 10 Loss : 0.142 \n",
      "Epoch : 10 Loss : 0.140 \n",
      "Epoch : 10 Loss : 0.141 \n",
      "Epoch : 10 Loss : 0.142 \n",
      "Epoch : 10 Loss : 0.140 \n",
      "Epoch : 10 Loss : 0.142 \n",
      "Epoch : 10 Loss : 0.141 \n",
      "Epoch : 10 Loss : 0.141 \n",
      "Epoch : 10 Loss : 0.139 \n",
      "Epoch : 10 Loss : 0.139 \n",
      "Epoch : 10 Loss : 0.139 \n",
      "Epoch : 10 Loss : 0.139 \n",
      "Epoch : 10 Loss : 0.138 \n",
      "Epoch : 10 Loss : 0.137 \n",
      "Epoch : 10 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 11 Loss : 0.106 \n",
      "Epoch : 11 Loss : 0.124 \n",
      "Epoch : 11 Loss : 0.132 \n",
      "Epoch : 11 Loss : 0.139 \n",
      "Epoch : 11 Loss : 0.137 \n",
      "Epoch : 11 Loss : 0.136 \n",
      "Epoch : 11 Loss : 0.134 \n",
      "Epoch : 11 Loss : 0.132 \n",
      "Epoch : 11 Loss : 0.134 \n",
      "Epoch : 11 Loss : 0.133 \n",
      "Epoch : 11 Loss : 0.136 \n",
      "Epoch : 11 Loss : 0.136 \n",
      "Epoch : 11 Loss : 0.136 \n",
      "Epoch : 11 Loss : 0.135 \n",
      "Epoch : 11 Loss : 0.135 \n",
      "Epoch : 11 Loss : 0.135 \n",
      "Epoch : 11 Loss : 0.135 \n",
      "Epoch : 11 Loss : 0.134 \n",
      "Epoch : 11 Loss : 0.134 \n",
      "Epoch : 11 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 12 Loss : 0.359 \n",
      "Epoch : 12 Loss : 0.138 \n",
      "Epoch : 12 Loss : 0.130 \n",
      "Epoch : 12 Loss : 0.132 \n",
      "Epoch : 12 Loss : 0.133 \n",
      "Epoch : 12 Loss : 0.129 \n",
      "Epoch : 12 Loss : 0.126 \n",
      "Epoch : 12 Loss : 0.125 \n",
      "Epoch : 12 Loss : 0.125 \n",
      "Epoch : 12 Loss : 0.124 \n",
      "Epoch : 12 Loss : 0.123 \n",
      "Epoch : 12 Loss : 0.124 \n",
      "Epoch : 12 Loss : 0.124 \n",
      "Epoch : 12 Loss : 0.123 \n",
      "Epoch : 12 Loss : 0.122 \n",
      "Epoch : 12 Loss : 0.122 \n",
      "Epoch : 12 Loss : 0.122 \n",
      "Epoch : 12 Loss : 0.122 \n",
      "Epoch : 12 Loss : 0.123 \n",
      "Epoch : 12 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 13 Loss : 0.119 \n",
      "Epoch : 13 Loss : 0.111 \n",
      "Epoch : 13 Loss : 0.121 \n",
      "Epoch : 13 Loss : 0.122 \n",
      "Epoch : 13 Loss : 0.121 \n",
      "Epoch : 13 Loss : 0.119 \n",
      "Epoch : 13 Loss : 0.121 \n",
      "Epoch : 13 Loss : 0.120 \n",
      "Epoch : 13 Loss : 0.118 \n",
      "Epoch : 13 Loss : 0.117 \n",
      "Epoch : 13 Loss : 0.116 \n",
      "Epoch : 13 Loss : 0.116 \n",
      "Epoch : 13 Loss : 0.118 \n",
      "Epoch : 13 Loss : 0.118 \n",
      "Epoch : 13 Loss : 0.118 \n",
      "Epoch : 13 Loss : 0.117 \n",
      "Epoch : 13 Loss : 0.117 \n",
      "Epoch : 13 Loss : 0.117 \n",
      "Epoch : 13 Loss : 0.116 \n",
      "Epoch : 13 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 14 Loss : 0.091 \n",
      "Epoch : 14 Loss : 0.113 \n",
      "Epoch : 14 Loss : 0.110 \n",
      "Epoch : 14 Loss : 0.113 \n",
      "Epoch : 14 Loss : 0.114 \n",
      "Epoch : 14 Loss : 0.111 \n",
      "Epoch : 14 Loss : 0.112 \n",
      "Epoch : 14 Loss : 0.112 \n",
      "Epoch : 14 Loss : 0.112 \n",
      "Epoch : 14 Loss : 0.111 \n",
      "Epoch : 14 Loss : 0.110 \n",
      "Epoch : 14 Loss : 0.111 \n",
      "Epoch : 14 Loss : 0.111 \n",
      "Epoch : 14 Loss : 0.111 \n",
      "Epoch : 14 Loss : 0.112 \n",
      "Epoch : 14 Loss : 0.112 \n",
      "Epoch : 14 Loss : 0.112 \n",
      "Epoch : 14 Loss : 0.112 \n",
      "Epoch : 14 Loss : 0.111 \n",
      "Epoch : 14 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 15 Loss : 0.158 \n",
      "Epoch : 15 Loss : 0.120 \n",
      "Epoch : 15 Loss : 0.106 \n",
      "Epoch : 15 Loss : 0.109 \n",
      "Epoch : 15 Loss : 0.110 \n",
      "Epoch : 15 Loss : 0.111 \n",
      "Epoch : 15 Loss : 0.111 \n",
      "Epoch : 15 Loss : 0.109 \n",
      "Epoch : 15 Loss : 0.108 \n",
      "Epoch : 15 Loss : 0.107 \n",
      "Epoch : 15 Loss : 0.106 \n",
      "Epoch : 15 Loss : 0.106 \n",
      "Epoch : 15 Loss : 0.106 \n",
      "Epoch : 15 Loss : 0.107 \n",
      "Epoch : 15 Loss : 0.107 \n",
      "Epoch : 15 Loss : 0.107 \n",
      "Epoch : 15 Loss : 0.108 \n",
      "Epoch : 15 Loss : 0.108 \n",
      "Epoch : 15 Loss : 0.108 \n",
      "Epoch : 15 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 16 Loss : 0.076 \n",
      "Epoch : 16 Loss : 0.102 \n",
      "Epoch : 16 Loss : 0.108 \n",
      "Epoch : 16 Loss : 0.105 \n",
      "Epoch : 16 Loss : 0.106 \n",
      "Epoch : 16 Loss : 0.105 \n",
      "Epoch : 16 Loss : 0.105 \n",
      "Epoch : 16 Loss : 0.105 \n",
      "Epoch : 16 Loss : 0.103 \n",
      "Epoch : 16 Loss : 0.103 \n",
      "Epoch : 16 Loss : 0.106 \n",
      "Epoch : 16 Loss : 0.108 \n",
      "Epoch : 16 Loss : 0.108 \n",
      "Epoch : 16 Loss : 0.108 \n",
      "Epoch : 16 Loss : 0.107 \n",
      "Epoch : 16 Loss : 0.107 \n",
      "Epoch : 16 Loss : 0.107 \n",
      "Epoch : 16 Loss : 0.107 \n",
      "Epoch : 16 Loss : 0.107 \n",
      "Epoch : 16 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 17 Loss : 0.024 \n",
      "Epoch : 17 Loss : 0.089 \n",
      "Epoch : 17 Loss : 0.095 \n",
      "Epoch : 17 Loss : 0.103 \n",
      "Epoch : 17 Loss : 0.102 \n",
      "Epoch : 17 Loss : 0.103 \n",
      "Epoch : 17 Loss : 0.106 \n",
      "Epoch : 17 Loss : 0.106 \n",
      "Epoch : 17 Loss : 0.105 \n",
      "Epoch : 17 Loss : 0.105 \n",
      "Epoch : 17 Loss : 0.105 \n",
      "Epoch : 17 Loss : 0.105 \n",
      "Epoch : 17 Loss : 0.104 \n",
      "Epoch : 17 Loss : 0.104 \n",
      "Epoch : 17 Loss : 0.104 \n",
      "Epoch : 17 Loss : 0.104 \n",
      "Epoch : 17 Loss : 0.103 \n",
      "Epoch : 17 Loss : 0.102 \n",
      "Epoch : 17 Loss : 0.103 \n",
      "Epoch : 17 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 18 Loss : 0.070 \n",
      "Epoch : 18 Loss : 0.093 \n",
      "Epoch : 18 Loss : 0.097 \n",
      "Epoch : 18 Loss : 0.096 \n",
      "Epoch : 18 Loss : 0.100 \n",
      "Epoch : 18 Loss : 0.100 \n",
      "Epoch : 18 Loss : 0.098 \n",
      "Epoch : 18 Loss : 0.100 \n",
      "Epoch : 18 Loss : 0.099 \n",
      "Epoch : 18 Loss : 0.101 \n",
      "Epoch : 18 Loss : 0.100 \n",
      "Epoch : 18 Loss : 0.100 \n",
      "Epoch : 18 Loss : 0.100 \n",
      "Epoch : 18 Loss : 0.101 \n",
      "Epoch : 18 Loss : 0.101 \n",
      "Epoch : 18 Loss : 0.101 \n",
      "Epoch : 18 Loss : 0.101 \n",
      "Epoch : 18 Loss : 0.101 \n",
      "Epoch : 18 Loss : 0.101 \n",
      "Epoch : 18 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 19 Loss : 0.131 \n",
      "Epoch : 19 Loss : 0.103 \n",
      "Epoch : 19 Loss : 0.099 \n",
      "Epoch : 19 Loss : 0.096 \n",
      "Epoch : 19 Loss : 0.096 \n",
      "Epoch : 19 Loss : 0.096 \n",
      "Epoch : 19 Loss : 0.097 \n",
      "Epoch : 19 Loss : 0.095 \n",
      "Epoch : 19 Loss : 0.095 \n",
      "Epoch : 19 Loss : 0.095 \n",
      "Epoch : 19 Loss : 0.095 \n",
      "Epoch : 19 Loss : 0.094 \n",
      "Epoch : 19 Loss : 0.096 \n",
      "Epoch : 19 Loss : 0.097 \n",
      "Epoch : 19 Loss : 0.097 \n",
      "Epoch : 19 Loss : 0.097 \n",
      "Epoch : 19 Loss : 0.097 \n",
      "Epoch : 19 Loss : 0.097 \n",
      "Epoch : 19 Loss : 0.097 \n",
      "Epoch : 19 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 20 Loss : 0.137 \n",
      "Epoch : 20 Loss : 0.101 \n",
      "Epoch : 20 Loss : 0.099 \n",
      "Epoch : 20 Loss : 0.096 \n",
      "Epoch : 20 Loss : 0.095 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.096 \n",
      "Epoch : 20 Loss : 0.096 \n",
      "Epoch : 20 Loss : 0.096 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Loss : 0.097 \n",
      "Epoch : 20 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 21 Loss : 0.025 \n",
      "Epoch : 21 Loss : 0.093 \n",
      "Epoch : 21 Loss : 0.096 \n",
      "Epoch : 21 Loss : 0.102 \n",
      "Epoch : 21 Loss : 0.100 \n",
      "Epoch : 21 Loss : 0.098 \n",
      "Epoch : 21 Loss : 0.097 \n",
      "Epoch : 21 Loss : 0.099 \n",
      "Epoch : 21 Loss : 0.098 \n",
      "Epoch : 21 Loss : 0.096 \n",
      "Epoch : 21 Loss : 0.096 \n",
      "Epoch : 21 Loss : 0.096 \n",
      "Epoch : 21 Loss : 0.097 \n",
      "Epoch : 21 Loss : 0.096 \n",
      "Epoch : 21 Loss : 0.095 \n",
      "Epoch : 21 Loss : 0.095 \n",
      "Epoch : 21 Loss : 0.094 \n",
      "Epoch : 21 Loss : 0.094 \n",
      "Epoch : 21 Loss : 0.094 \n",
      "Epoch : 21 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 22 Loss : 0.207 \n",
      "Epoch : 22 Loss : 0.085 \n",
      "Epoch : 22 Loss : 0.084 \n",
      "Epoch : 22 Loss : 0.091 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.089 \n",
      "Epoch : 22 Loss : 0.091 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.089 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Loss : 0.090 \n",
      "Epoch : 22 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 23 Loss : 0.057 \n",
      "Epoch : 23 Loss : 0.098 \n",
      "Epoch : 23 Loss : 0.100 \n",
      "Epoch : 23 Loss : 0.097 \n",
      "Epoch : 23 Loss : 0.095 \n",
      "Epoch : 23 Loss : 0.094 \n",
      "Epoch : 23 Loss : 0.094 \n",
      "Epoch : 23 Loss : 0.094 \n",
      "Epoch : 23 Loss : 0.094 \n",
      "Epoch : 23 Loss : 0.091 \n",
      "Epoch : 23 Loss : 0.089 \n",
      "Epoch : 23 Loss : 0.090 \n",
      "Epoch : 23 Loss : 0.090 \n",
      "Epoch : 23 Loss : 0.091 \n",
      "Epoch : 23 Loss : 0.090 \n",
      "Epoch : 23 Loss : 0.090 \n",
      "Epoch : 23 Loss : 0.090 \n",
      "Epoch : 23 Loss : 0.089 \n",
      "Epoch : 23 Loss : 0.089 \n",
      "Epoch : 23 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 24 Loss : 0.052 \n",
      "Epoch : 24 Loss : 0.075 \n",
      "Epoch : 24 Loss : 0.077 \n",
      "Epoch : 24 Loss : 0.085 \n",
      "Epoch : 24 Loss : 0.082 \n",
      "Epoch : 24 Loss : 0.085 \n",
      "Epoch : 24 Loss : 0.083 \n",
      "Epoch : 24 Loss : 0.084 \n",
      "Epoch : 24 Loss : 0.082 \n",
      "Epoch : 24 Loss : 0.083 \n",
      "Epoch : 24 Loss : 0.083 \n",
      "Epoch : 24 Loss : 0.084 \n",
      "Epoch : 24 Loss : 0.084 \n",
      "Epoch : 24 Loss : 0.084 \n",
      "Epoch : 24 Loss : 0.084 \n",
      "Epoch : 24 Loss : 0.084 \n",
      "Epoch : 24 Loss : 0.085 \n",
      "Epoch : 24 Loss : 0.087 \n",
      "Epoch : 24 Loss : 0.087 \n",
      "Epoch : 24 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 25 Loss : 0.087 \n",
      "Epoch : 25 Loss : 0.075 \n",
      "Epoch : 25 Loss : 0.081 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.082 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.084 \n",
      "Epoch : 25 Loss : 0.084 \n",
      "Epoch : 25 Loss : 0.082 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.082 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.084 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Loss : 0.083 \n",
      "Epoch : 25 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 26 Loss : 0.161 \n",
      "Epoch : 26 Loss : 0.085 \n",
      "Epoch : 26 Loss : 0.093 \n",
      "Epoch : 26 Loss : 0.091 \n",
      "Epoch : 26 Loss : 0.089 \n",
      "Epoch : 26 Loss : 0.087 \n",
      "Epoch : 26 Loss : 0.087 \n",
      "Epoch : 26 Loss : 0.086 \n",
      "Epoch : 26 Loss : 0.085 \n",
      "Epoch : 26 Loss : 0.083 \n",
      "Epoch : 26 Loss : 0.083 \n",
      "Epoch : 26 Loss : 0.082 \n",
      "Epoch : 26 Loss : 0.082 \n",
      "Epoch : 26 Loss : 0.081 \n",
      "Epoch : 26 Loss : 0.081 \n",
      "Epoch : 26 Loss : 0.081 \n",
      "Epoch : 26 Loss : 0.080 \n",
      "Epoch : 26 Loss : 0.080 \n",
      "Epoch : 26 Loss : 0.081 \n",
      "Epoch : 26 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 27 Loss : 0.108 \n",
      "Epoch : 27 Loss : 0.083 \n",
      "Epoch : 27 Loss : 0.080 \n",
      "Epoch : 27 Loss : 0.080 \n",
      "Epoch : 27 Loss : 0.082 \n",
      "Epoch : 27 Loss : 0.083 \n",
      "Epoch : 27 Loss : 0.082 \n",
      "Epoch : 27 Loss : 0.080 \n",
      "Epoch : 27 Loss : 0.081 \n",
      "Epoch : 27 Loss : 0.083 \n",
      "Epoch : 27 Loss : 0.082 \n",
      "Epoch : 27 Loss : 0.082 \n",
      "Epoch : 27 Loss : 0.082 \n",
      "Epoch : 27 Loss : 0.081 \n",
      "Epoch : 27 Loss : 0.081 \n",
      "Epoch : 27 Loss : 0.080 \n",
      "Epoch : 27 Loss : 0.081 \n",
      "Epoch : 27 Loss : 0.081 \n",
      "Epoch : 27 Loss : 0.080 \n",
      "Epoch : 27 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 28 Loss : 0.060 \n",
      "Epoch : 28 Loss : 0.090 \n",
      "Epoch : 28 Loss : 0.081 \n",
      "Epoch : 28 Loss : 0.083 \n",
      "Epoch : 28 Loss : 0.084 \n",
      "Epoch : 28 Loss : 0.079 \n",
      "Epoch : 28 Loss : 0.077 \n",
      "Epoch : 28 Loss : 0.077 \n",
      "Epoch : 28 Loss : 0.077 \n",
      "Epoch : 28 Loss : 0.076 \n",
      "Epoch : 28 Loss : 0.075 \n",
      "Epoch : 28 Loss : 0.075 \n",
      "Epoch : 28 Loss : 0.076 \n",
      "Epoch : 28 Loss : 0.075 \n",
      "Epoch : 28 Loss : 0.075 \n",
      "Epoch : 28 Loss : 0.075 \n",
      "Epoch : 28 Loss : 0.075 \n",
      "Epoch : 28 Loss : 0.075 \n",
      "Epoch : 28 Loss : 0.075 \n",
      "Epoch : 28 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 29 Loss : 0.042 \n",
      "Epoch : 29 Loss : 0.077 \n",
      "Epoch : 29 Loss : 0.086 \n",
      "Epoch : 29 Loss : 0.084 \n",
      "Epoch : 29 Loss : 0.083 \n",
      "Epoch : 29 Loss : 0.082 \n",
      "Epoch : 29 Loss : 0.079 \n",
      "Epoch : 29 Loss : 0.077 \n",
      "Epoch : 29 Loss : 0.078 \n",
      "Epoch : 29 Loss : 0.078 \n",
      "Epoch : 29 Loss : 0.078 \n",
      "Epoch : 29 Loss : 0.078 \n",
      "Epoch : 29 Loss : 0.077 \n",
      "Epoch : 29 Loss : 0.077 \n",
      "Epoch : 29 Loss : 0.077 \n",
      "Epoch : 29 Loss : 0.077 \n",
      "Epoch : 29 Loss : 0.077 \n",
      "Epoch : 29 Loss : 0.076 \n",
      "Epoch : 29 Loss : 0.077 \n",
      "Epoch : 29 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 30 Loss : 0.063 \n",
      "Epoch : 30 Loss : 0.091 \n",
      "Epoch : 30 Loss : 0.082 \n",
      "Epoch : 30 Loss : 0.077 \n",
      "Epoch : 30 Loss : 0.080 \n",
      "Epoch : 30 Loss : 0.077 \n",
      "Epoch : 30 Loss : 0.077 \n",
      "Epoch : 30 Loss : 0.078 \n",
      "Epoch : 30 Loss : 0.077 \n",
      "Epoch : 30 Loss : 0.076 \n",
      "Epoch : 30 Loss : 0.076 \n",
      "Epoch : 30 Loss : 0.077 \n",
      "Epoch : 30 Loss : 0.076 \n",
      "Epoch : 30 Loss : 0.076 \n",
      "Epoch : 30 Loss : 0.075 \n",
      "Epoch : 30 Loss : 0.076 \n",
      "Epoch : 30 Loss : 0.076 \n",
      "Epoch : 30 Loss : 0.076 \n",
      "Epoch : 30 Loss : 0.076 \n",
      "Epoch : 30 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 31 Loss : 0.064 \n",
      "Epoch : 31 Loss : 0.060 \n",
      "Epoch : 31 Loss : 0.072 \n",
      "Epoch : 31 Loss : 0.071 \n",
      "Epoch : 31 Loss : 0.073 \n",
      "Epoch : 31 Loss : 0.074 \n",
      "Epoch : 31 Loss : 0.074 \n",
      "Epoch : 31 Loss : 0.073 \n",
      "Epoch : 31 Loss : 0.072 \n",
      "Epoch : 31 Loss : 0.073 \n",
      "Epoch : 31 Loss : 0.074 \n",
      "Epoch : 31 Loss : 0.074 \n",
      "Epoch : 31 Loss : 0.074 \n",
      "Epoch : 31 Loss : 0.073 \n",
      "Epoch : 31 Loss : 0.073 \n",
      "Epoch : 31 Loss : 0.073 \n",
      "Epoch : 31 Loss : 0.073 \n",
      "Epoch : 31 Loss : 0.074 \n",
      "Epoch : 31 Loss : 0.074 \n",
      "Epoch : 31 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 32 Loss : 0.112 \n",
      "Epoch : 32 Loss : 0.065 \n",
      "Epoch : 32 Loss : 0.070 \n",
      "Epoch : 32 Loss : 0.073 \n",
      "Epoch : 32 Loss : 0.071 \n",
      "Epoch : 32 Loss : 0.069 \n",
      "Epoch : 32 Loss : 0.069 \n",
      "Epoch : 32 Loss : 0.068 \n",
      "Epoch : 32 Loss : 0.069 \n",
      "Epoch : 32 Loss : 0.070 \n",
      "Epoch : 32 Loss : 0.070 \n",
      "Epoch : 32 Loss : 0.070 \n",
      "Epoch : 32 Loss : 0.071 \n",
      "Epoch : 32 Loss : 0.071 \n",
      "Epoch : 32 Loss : 0.072 \n",
      "Epoch : 32 Loss : 0.073 \n",
      "Epoch : 32 Loss : 0.073 \n",
      "Epoch : 32 Loss : 0.073 \n",
      "Epoch : 32 Loss : 0.073 \n",
      "Epoch : 32 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 33 Loss : 0.029 \n",
      "Epoch : 33 Loss : 0.067 \n",
      "Epoch : 33 Loss : 0.072 \n",
      "Epoch : 33 Loss : 0.068 \n",
      "Epoch : 33 Loss : 0.067 \n",
      "Epoch : 33 Loss : 0.069 \n",
      "Epoch : 33 Loss : 0.071 \n",
      "Epoch : 33 Loss : 0.069 \n",
      "Epoch : 33 Loss : 0.069 \n",
      "Epoch : 33 Loss : 0.069 \n",
      "Epoch : 33 Loss : 0.070 \n",
      "Epoch : 33 Loss : 0.070 \n",
      "Epoch : 33 Loss : 0.071 \n",
      "Epoch : 33 Loss : 0.070 \n",
      "Epoch : 33 Loss : 0.071 \n",
      "Epoch : 33 Loss : 0.071 \n",
      "Epoch : 33 Loss : 0.071 \n",
      "Epoch : 33 Loss : 0.071 \n",
      "Epoch : 33 Loss : 0.071 \n",
      "Epoch : 33 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 34 Loss : 0.010 \n",
      "Epoch : 34 Loss : 0.071 \n",
      "Epoch : 34 Loss : 0.072 \n",
      "Epoch : 34 Loss : 0.068 \n",
      "Epoch : 34 Loss : 0.069 \n",
      "Epoch : 34 Loss : 0.068 \n",
      "Epoch : 34 Loss : 0.067 \n",
      "Epoch : 34 Loss : 0.067 \n",
      "Epoch : 34 Loss : 0.069 \n",
      "Epoch : 34 Loss : 0.069 \n",
      "Epoch : 34 Loss : 0.068 \n",
      "Epoch : 34 Loss : 0.069 \n",
      "Epoch : 34 Loss : 0.070 \n",
      "Epoch : 34 Loss : 0.070 \n",
      "Epoch : 34 Loss : 0.070 \n",
      "Epoch : 34 Loss : 0.070 \n",
      "Epoch : 34 Loss : 0.069 \n",
      "Epoch : 34 Loss : 0.069 \n",
      "Epoch : 34 Loss : 0.069 \n",
      "Epoch : 34 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 35 Loss : 0.031 \n",
      "Epoch : 35 Loss : 0.066 \n",
      "Epoch : 35 Loss : 0.067 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.066 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.067 \n",
      "Epoch : 35 Loss : 0.067 \n",
      "Epoch : 35 Loss : 0.067 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Loss : 0.068 \n",
      "Epoch : 35 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 36 Loss : 0.082 \n",
      "Epoch : 36 Loss : 0.065 \n",
      "Epoch : 36 Loss : 0.065 \n",
      "Epoch : 36 Loss : 0.071 \n",
      "Epoch : 36 Loss : 0.071 \n",
      "Epoch : 36 Loss : 0.069 \n",
      "Epoch : 36 Loss : 0.069 \n",
      "Epoch : 36 Loss : 0.068 \n",
      "Epoch : 36 Loss : 0.066 \n",
      "Epoch : 36 Loss : 0.066 \n",
      "Epoch : 36 Loss : 0.065 \n",
      "Epoch : 36 Loss : 0.064 \n",
      "Epoch : 36 Loss : 0.064 \n",
      "Epoch : 36 Loss : 0.066 \n",
      "Epoch : 36 Loss : 0.065 \n",
      "Epoch : 36 Loss : 0.065 \n",
      "Epoch : 36 Loss : 0.066 \n",
      "Epoch : 36 Loss : 0.066 \n",
      "Epoch : 36 Loss : 0.066 \n",
      "Epoch : 36 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 37 Loss : 0.048 \n",
      "Epoch : 37 Loss : 0.063 \n",
      "Epoch : 37 Loss : 0.066 \n",
      "Epoch : 37 Loss : 0.067 \n",
      "Epoch : 37 Loss : 0.066 \n",
      "Epoch : 37 Loss : 0.064 \n",
      "Epoch : 37 Loss : 0.066 \n",
      "Epoch : 37 Loss : 0.067 \n",
      "Epoch : 37 Loss : 0.065 \n",
      "Epoch : 37 Loss : 0.066 \n",
      "Epoch : 37 Loss : 0.065 \n",
      "Epoch : 37 Loss : 0.065 \n",
      "Epoch : 37 Loss : 0.066 \n",
      "Epoch : 37 Loss : 0.067 \n",
      "Epoch : 37 Loss : 0.067 \n",
      "Epoch : 37 Loss : 0.067 \n",
      "Epoch : 37 Loss : 0.067 \n",
      "Epoch : 37 Loss : 0.068 \n",
      "Epoch : 37 Loss : 0.068 \n",
      "Epoch : 37 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 38 Loss : 0.025 \n",
      "Epoch : 38 Loss : 0.059 \n",
      "Epoch : 38 Loss : 0.063 \n",
      "Epoch : 38 Loss : 0.061 \n",
      "Epoch : 38 Loss : 0.060 \n",
      "Epoch : 38 Loss : 0.064 \n",
      "Epoch : 38 Loss : 0.065 \n",
      "Epoch : 38 Loss : 0.065 \n",
      "Epoch : 38 Loss : 0.064 \n",
      "Epoch : 38 Loss : 0.064 \n",
      "Epoch : 38 Loss : 0.063 \n",
      "Epoch : 38 Loss : 0.063 \n",
      "Epoch : 38 Loss : 0.064 \n",
      "Epoch : 38 Loss : 0.065 \n",
      "Epoch : 38 Loss : 0.065 \n",
      "Epoch : 38 Loss : 0.065 \n",
      "Epoch : 38 Loss : 0.064 \n",
      "Epoch : 38 Loss : 0.064 \n",
      "Epoch : 38 Loss : 0.065 \n",
      "Epoch : 38 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 39 Loss : 0.097 \n",
      "Epoch : 39 Loss : 0.065 \n",
      "Epoch : 39 Loss : 0.063 \n",
      "Epoch : 39 Loss : 0.062 \n",
      "Epoch : 39 Loss : 0.062 \n",
      "Epoch : 39 Loss : 0.062 \n",
      "Epoch : 39 Loss : 0.066 \n",
      "Epoch : 39 Loss : 0.067 \n",
      "Epoch : 39 Loss : 0.066 \n",
      "Epoch : 39 Loss : 0.065 \n",
      "Epoch : 39 Loss : 0.066 \n",
      "Epoch : 39 Loss : 0.064 \n",
      "Epoch : 39 Loss : 0.064 \n",
      "Epoch : 39 Loss : 0.063 \n",
      "Epoch : 39 Loss : 0.063 \n",
      "Epoch : 39 Loss : 0.063 \n",
      "Epoch : 39 Loss : 0.063 \n",
      "Epoch : 39 Loss : 0.064 \n",
      "Epoch : 39 Loss : 0.063 \n",
      "Epoch : 39 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 40 Loss : 0.023 \n",
      "Epoch : 40 Loss : 0.057 \n",
      "Epoch : 40 Loss : 0.068 \n",
      "Epoch : 40 Loss : 0.067 \n",
      "Epoch : 40 Loss : 0.066 \n",
      "Epoch : 40 Loss : 0.068 \n",
      "Epoch : 40 Loss : 0.067 \n",
      "Epoch : 40 Loss : 0.066 \n",
      "Epoch : 40 Loss : 0.065 \n",
      "Epoch : 40 Loss : 0.065 \n",
      "Epoch : 40 Loss : 0.066 \n",
      "Epoch : 40 Loss : 0.065 \n",
      "Epoch : 40 Loss : 0.065 \n",
      "Epoch : 40 Loss : 0.064 \n",
      "Epoch : 40 Loss : 0.065 \n",
      "Epoch : 40 Loss : 0.065 \n",
      "Epoch : 40 Loss : 0.065 \n",
      "Epoch : 40 Loss : 0.064 \n",
      "Epoch : 40 Loss : 0.064 \n",
      "Epoch : 40 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 41 Loss : 0.014 \n",
      "Epoch : 41 Loss : 0.058 \n",
      "Epoch : 41 Loss : 0.057 \n",
      "Epoch : 41 Loss : 0.062 \n",
      "Epoch : 41 Loss : 0.063 \n",
      "Epoch : 41 Loss : 0.062 \n",
      "Epoch : 41 Loss : 0.062 \n",
      "Epoch : 41 Loss : 0.062 \n",
      "Epoch : 41 Loss : 0.062 \n",
      "Epoch : 41 Loss : 0.062 \n",
      "Epoch : 41 Loss : 0.062 \n",
      "Epoch : 41 Loss : 0.063 \n",
      "Epoch : 41 Loss : 0.063 \n",
      "Epoch : 41 Loss : 0.062 \n",
      "Epoch : 41 Loss : 0.063 \n",
      "Epoch : 41 Loss : 0.063 \n",
      "Epoch : 41 Loss : 0.063 \n",
      "Epoch : 41 Loss : 0.064 \n",
      "Epoch : 41 Loss : 0.063 \n",
      "Epoch : 41 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 42 Loss : 0.007 \n",
      "Epoch : 42 Loss : 0.058 \n",
      "Epoch : 42 Loss : 0.062 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Loss : 0.064 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Loss : 0.062 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Loss : 0.064 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Loss : 0.062 \n",
      "Epoch : 42 Loss : 0.062 \n",
      "Epoch : 42 Loss : 0.062 \n",
      "Epoch : 42 Loss : 0.062 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Loss : 0.063 \n",
      "Epoch : 42 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 43 Loss : 0.020 \n",
      "Epoch : 43 Loss : 0.054 \n",
      "Epoch : 43 Loss : 0.054 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.061 \n",
      "Epoch : 43 Loss : 0.061 \n",
      "Epoch : 43 Loss : 0.061 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.061 \n",
      "Epoch : 43 Loss : 0.061 \n",
      "Epoch : 43 Loss : 0.061 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Loss : 0.060 \n",
      "Epoch : 43 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 44 Loss : 0.126 \n",
      "Epoch : 44 Loss : 0.049 \n",
      "Epoch : 44 Loss : 0.054 \n",
      "Epoch : 44 Loss : 0.056 \n",
      "Epoch : 44 Loss : 0.060 \n",
      "Epoch : 44 Loss : 0.061 \n",
      "Epoch : 44 Loss : 0.061 \n",
      "Epoch : 44 Loss : 0.060 \n",
      "Epoch : 44 Loss : 0.059 \n",
      "Epoch : 44 Loss : 0.060 \n",
      "Epoch : 44 Loss : 0.060 \n",
      "Epoch : 44 Loss : 0.059 \n",
      "Epoch : 44 Loss : 0.059 \n",
      "Epoch : 44 Loss : 0.058 \n",
      "Epoch : 44 Loss : 0.059 \n",
      "Epoch : 44 Loss : 0.059 \n",
      "Epoch : 44 Loss : 0.059 \n",
      "Epoch : 44 Loss : 0.060 \n",
      "Epoch : 44 Loss : 0.060 \n",
      "Epoch : 44 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 45 Loss : 0.180 \n",
      "Epoch : 45 Loss : 0.080 \n",
      "Epoch : 45 Loss : 0.069 \n",
      "Epoch : 45 Loss : 0.067 \n",
      "Epoch : 45 Loss : 0.066 \n",
      "Epoch : 45 Loss : 0.062 \n",
      "Epoch : 45 Loss : 0.059 \n",
      "Epoch : 45 Loss : 0.062 \n",
      "Epoch : 45 Loss : 0.063 \n",
      "Epoch : 45 Loss : 0.063 \n",
      "Epoch : 45 Loss : 0.064 \n",
      "Epoch : 45 Loss : 0.064 \n",
      "Epoch : 45 Loss : 0.064 \n",
      "Epoch : 45 Loss : 0.063 \n",
      "Epoch : 45 Loss : 0.062 \n",
      "Epoch : 45 Loss : 0.061 \n",
      "Epoch : 45 Loss : 0.061 \n",
      "Epoch : 45 Loss : 0.061 \n",
      "Epoch : 45 Loss : 0.061 \n",
      "Epoch : 45 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 46 Loss : 0.032 \n",
      "Epoch : 46 Loss : 0.063 \n",
      "Epoch : 46 Loss : 0.064 \n",
      "Epoch : 46 Loss : 0.061 \n",
      "Epoch : 46 Loss : 0.063 \n",
      "Epoch : 46 Loss : 0.063 \n",
      "Epoch : 46 Loss : 0.063 \n",
      "Epoch : 46 Loss : 0.061 \n",
      "Epoch : 46 Loss : 0.060 \n",
      "Epoch : 46 Loss : 0.061 \n",
      "Epoch : 46 Loss : 0.061 \n",
      "Epoch : 46 Loss : 0.060 \n",
      "Epoch : 46 Loss : 0.060 \n",
      "Epoch : 46 Loss : 0.060 \n",
      "Epoch : 46 Loss : 0.060 \n",
      "Epoch : 46 Loss : 0.061 \n",
      "Epoch : 46 Loss : 0.061 \n",
      "Epoch : 46 Loss : 0.061 \n",
      "Epoch : 46 Loss : 0.061 \n",
      "Epoch : 46 Test Acc : 98.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 47 Loss : 0.117 \n",
      "Epoch : 47 Loss : 0.055 \n",
      "Epoch : 47 Loss : 0.056 \n",
      "Epoch : 47 Loss : 0.056 \n",
      "Epoch : 47 Loss : 0.056 \n",
      "Epoch : 47 Loss : 0.054 \n",
      "Epoch : 47 Loss : 0.056 \n",
      "Epoch : 47 Loss : 0.057 \n",
      "Epoch : 47 Loss : 0.058 \n",
      "Epoch : 47 Loss : 0.058 \n",
      "Epoch : 47 Loss : 0.060 \n",
      "Epoch : 47 Loss : 0.060 \n",
      "Epoch : 47 Loss : 0.059 \n",
      "Epoch : 47 Loss : 0.060 \n",
      "Epoch : 47 Loss : 0.060 \n",
      "Epoch : 47 Loss : 0.059 \n",
      "Epoch : 47 Loss : 0.059 \n",
      "Epoch : 47 Loss : 0.059 \n",
      "Epoch : 47 Loss : 0.059 \n",
      "Epoch : 47 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 48 Loss : 0.099 \n",
      "Epoch : 48 Loss : 0.053 \n",
      "Epoch : 48 Loss : 0.057 \n",
      "Epoch : 48 Loss : 0.060 \n",
      "Epoch : 48 Loss : 0.058 \n",
      "Epoch : 48 Loss : 0.058 \n",
      "Epoch : 48 Loss : 0.056 \n",
      "Epoch : 48 Loss : 0.056 \n",
      "Epoch : 48 Loss : 0.056 \n",
      "Epoch : 48 Loss : 0.057 \n",
      "Epoch : 48 Loss : 0.057 \n",
      "Epoch : 48 Loss : 0.057 \n",
      "Epoch : 48 Loss : 0.057 \n",
      "Epoch : 48 Loss : 0.058 \n",
      "Epoch : 48 Loss : 0.057 \n",
      "Epoch : 48 Loss : 0.058 \n",
      "Epoch : 48 Loss : 0.058 \n",
      "Epoch : 48 Loss : 0.058 \n",
      "Epoch : 48 Loss : 0.059 \n",
      "Epoch : 48 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n",
      "Epoch : 49 Loss : 0.137 \n",
      "Epoch : 49 Loss : 0.057 \n",
      "Epoch : 49 Loss : 0.062 \n",
      "Epoch : 49 Loss : 0.058 \n",
      "Epoch : 49 Loss : 0.056 \n",
      "Epoch : 49 Loss : 0.056 \n",
      "Epoch : 49 Loss : 0.056 \n",
      "Epoch : 49 Loss : 0.055 \n",
      "Epoch : 49 Loss : 0.055 \n",
      "Epoch : 49 Loss : 0.055 \n",
      "Epoch : 49 Loss : 0.056 \n",
      "Epoch : 49 Loss : 0.057 \n",
      "Epoch : 49 Loss : 0.058 \n",
      "Epoch : 49 Loss : 0.057 \n",
      "Epoch : 49 Loss : 0.058 \n",
      "Epoch : 49 Loss : 0.058 \n",
      "Epoch : 49 Loss : 0.058 \n",
      "Epoch : 49 Loss : 0.058 \n",
      "Epoch : 49 Loss : 0.058 \n",
      "Epoch : 49 Test Acc : 99.000\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    losses = []\n",
    "    # Train\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        if cuda_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = clf(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "        if batch_idx%50==0:\n",
    "            print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))\n",
    "    \n",
    "    # Evaluate\n",
    "    clf.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        if cuda_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        outputs = clf(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    print('Epoch : %d Test Acc : %.3f' % (epoch, 100.*correct/total))\n",
    "    print('--------------------------------------------------------------')\n",
    "    clf.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
